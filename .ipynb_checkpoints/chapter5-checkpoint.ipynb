{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a556da-e4cd-4d93-a2aa-d7157f239972",
   "metadata": {},
   "source": [
    "# Principal kernel recursion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cd82aa-5726-40e0-8b88-3a495068fafa",
   "metadata": {},
   "source": [
    "We want to explicitly check the validity of Eq. 5.4 of arXiv:2106.10165. To this end we write down a NN with 5 hidden layers, each with nL neurons, with user-specified activation function. Then we extract the value of $K_{00}$ at the 3-rd and 4-th layer and check if they are indeed related by Eq. 5.4 (within error-bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "8c8c67bc-5673-4b3e-b638-38f4c7b58905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.integrate as integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70d4d88-3b3a-4166-ad1e-f4bd1f91823b",
   "metadata": {},
   "source": [
    "Hyperparameters of the network. n_inputs is the number of inputs, not to be confused with n_samples, which is the number of times we initialize the network, i.e. the dimension of the ensemble of networks we use to measure statistics (like means and variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "194aabaa-c846-4a6f-b8fb-0e7d6e94f324",
   "metadata": {},
   "outputs": [],
   "source": [
    "nL = 200\n",
    "cw = 10\n",
    "cb = 0.\n",
    "n_inputs = 100\n",
    "n_samples = 100\n",
    "in_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69029673-619a-425a-9e37-517065c709fb",
   "metadata": {},
   "source": [
    "Network class. Here we have 1 input layer with \"in_size\" inputs and \"nL\" outputs, 5 hidden layers with \"nL\" inputs and \"nL\" outputs, and one output layer with \"nL\" inputs and 1 output. We pick the preactivations z3 and z4 from the 3rd and 4th hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "e37d8ee1-c34c-4d08-b7a8-381fba12841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple_NN, self).__init__()\n",
    "        self.firstlayer = nn.Linear(in_features=in_size, out_features=nL)\n",
    "        self.layer1 = nn.Linear(nL, nL)\n",
    "        self.layer2 = nn.Linear(nL, nL)\n",
    "        self.layer3 = nn.Linear(nL, nL)\n",
    "        self.layer4 = nn.Linear(nL, nL)\n",
    "        self.layer5 = nn.Linear(nL, nL)\n",
    "        self.finallayer = nn.Linear(in_features=nL, out_features=1)\n",
    "        \n",
    "        # Initialize weights from a Gaussian distribution\n",
    "        init.normal_(self.firstlayer.weight, mean=0.0, std=np.sqrt(cw/n_inputs))\n",
    "        init.normal_(self.layer1.weight, mean=0.0, std=np.sqrt(cw/nL))\n",
    "        init.normal_(self.layer2.weight, mean=0.0, std=np.sqrt(cw/nL))\n",
    "        init.normal_(self.layer3.weight, mean=0.0, std=np.sqrt(cw/nL))\n",
    "        init.normal_(self.layer4.weight, mean=0.0, std=np.sqrt(cw/nL))\n",
    "        init.normal_(self.layer5.weight, mean=0.0, std=np.sqrt(cw/nL))\n",
    "        init.normal_(self.finallayer.weight, mean=0.0, std=np.sqrt(cw/nL))\n",
    "        \n",
    "        # Initialize biases from a Gaussian distribution\n",
    "        init.normal_(self.firstlayer.bias, mean=0.0, std=cb)\n",
    "        init.normal_(self.layer1.bias, mean=0.0, std=cb)\n",
    "        init.normal_(self.layer2.bias, mean=0.0, std=cb)\n",
    "        init.normal_(self.layer3.bias, mean=0.0, std=cb)\n",
    "        init.normal_(self.layer4.bias, mean=0.0, std=cb)\n",
    "        init.normal_(self.layer5.bias, mean=0.0, std=cb)\n",
    "        init.normal_(self.finallayer.bias, mean=0.0, std=cb)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z0 = x\n",
    "        z1 = self.firstlayer(x)\n",
    "        x = F.relu(z1)\n",
    "        z2 = self.layer1(x)\n",
    "        x = F.relu(z2)\n",
    "        z3 = self.layer2(x)\n",
    "        x = F.relu(z3)\n",
    "        z4 = self.layer3(x)\n",
    "        x = F.relu(z4)\n",
    "        z5 = self.layer4(x)\n",
    "        x = F.relu(z5)\n",
    "        z6 = self.layer5(x)\n",
    "        x = F.relu(z6)\n",
    "        x = self.finallayer(x) #the final layer has no Activation function applied to it\n",
    "        return x, z3, z4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "7cf836e3-7676-4c59-8a78-f6d2cc7717f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(n_inputs,in_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "89eb1a55-cd4d-40c8-afd0-8ae9d7267fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(k):\n",
    "    if not(torch.is_tensor(k)):\n",
    "        k = torch.tensor(k)\n",
    "    x = torch.linspace(-100,100,1000)\n",
    "    norm = torch.sqrt(2*np.pi*k.clone().detach())\n",
    "    return ((sum((F.relu(x)**2)*np.exp(-x**2/(2*k)))/norm)/1000)*200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1cf17-4e5b-41ea-ac6e-856a427ec51e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Since nL is pretty large, as a first approximation we take the kernel K, i.e. the first order approximation of the metric, to be the full metric. This is correct up to O(1/nL) corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c63f0e9-fbed-420c-8c8e-e7417cd6d37f",
   "metadata": {},
   "source": [
    "Without loss of generality we consider the 0-th input, compute the average of the kernel at the 3rd and 4th layer over n_samples initializations of the network, and check if it they are related by eq 5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "dbf8a5c0-5e22-48d8-bbb5-170c752e42f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0040)\n"
     ]
    }
   ],
   "source": [
    "k3vec = []\n",
    "k4vec = []\n",
    "for _ in range(n_samples):\n",
    "    model = Simple_NN()\n",
    "    xout, z3, z4 = model(x)\n",
    "    k3vec.append(sum((z3[0].detach())**2)/nL)\n",
    "    k4vec.append(sum((z4[0].detach())**2)/nL)\n",
    "\n",
    "k3 = np.mean(k3vec)\n",
    "k4 = np.mean(k4vec)\n",
    "k4exp = cb + cw * g(k3)\n",
    "print(k4/k4exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf673ada-62e7-4cf6-97fa-f32b7633f84f",
   "metadata": {},
   "source": [
    "## 2 - Find the critical value of K "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1588c3-8c50-4baa-b57e-4bb4ec2e7703",
   "metadata": {},
   "source": [
    "Here we want to reproduce the mechanism for finding criticality explained befor Eq. (5.73), with the goal of reproducing Fig. 5.2 (right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c22b08c-310b-4611-b15f-aca3c6545df3",
   "metadata": {},
   "source": [
    "Besides solving Eq. (5.73) graphycally, we also want to solve it numerically. To this end, we define a routine to solve equations witht the bisection method. First  we define an auxiliary function checking if two numbers are equal up to some numerical tolerance. We use it then in the next function to check if some value is 0 up to rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "122e2d09-07db-477e-b4dd-53b8ddc2bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp(x,y,eps = 1e-8):\n",
    "    if abs(x-y)<eps:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c43318-7d4e-4a9f-9e8e-02c4ff5f8fc6",
   "metadata": {},
   "source": [
    "This function actually runs the bisection algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "9fd5baf2-2e10-4ba5-a21f-13449ea93949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisect(f, a, b,*args,tolerance = 1e-6,max_iterations=1000):\n",
    "    # This routine only works for monotonic functions that cross 0 within the specified interval. \n",
    "    # If the function does not cross 0 within the interval, raise an error\n",
    "    if f(a,*args)*f(b,*args)>0 and not(comp(f(a,*args)*f(b,*args),0, eps = tolerance)):\n",
    "        raise ValueError(\"The function does not cross 0 within the interval\")\n",
    "        \n",
    "    # If the function is already 0 (within the tolerance) at one of the extremes, return the extreme\n",
    "    if comp(f(a, *args),0, eps = tolerance):\n",
    "        return a, f(a,*args)\n",
    "    if comp(f(b, *args),0, eps = tolerance):\n",
    "        return b, f(b,*args)\n",
    "    \n",
    "    # If the previous checks have gone through, just go ahead and run the bisection algorithm \n",
    "    for i in range(max_iterations):\n",
    "        bis_point = (b+a)/2\n",
    "        if comp(f(bis_point,*args),0, eps = tolerance):\n",
    "            return bis_point\n",
    "        elif f(bis_point,*args)*f(a,*args)>0:\n",
    "            a = bis_point\n",
    "        elif f(bis_point,*args)*f(b,*args)>0:\n",
    "            b = bis_point\n",
    "    raise ValueError(\"Bisection method did not converge within the maximum number of iterations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a826d-56ed-4d88-9ac3-b265f385ea92",
   "metadata": {},
   "source": [
    "## Find the fixed point value "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de10ba79-cbbc-49d6-a83e-b56bf51d88e5",
   "metadata": {},
   "source": [
    "This is just the activation function, wrapped in a flexible way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "24f57fb3-4aad-4af1-850e-62fd4ffb0597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_fun(x, act = \"ReLU\"):\n",
    "    if act in act_fun_dict.keys():\n",
    "        return act_fun_dict[act](x)\n",
    "    else:\n",
    "        raise ValueError(\"This activation function is unknown or unsupported at the moment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d3518-3a3b-4685-b444-83e980b0df83",
   "metadata": {},
   "source": [
    "To compute the LHS of eq. (5.73) we need the derivative of the activation function, computed here using autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "4cb845e8-1f3e-4e42-b34a-d33535de6b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def der_act(x, act = \"ReLU\"):\n",
    "    if act in act_fun_dict.keys():\n",
    "        if torch.is_tensor(x):\n",
    "            xgrad = []\n",
    "            for xi in x:\n",
    "                xi = xi.clone().detach().requires_grad_(True)\n",
    "                y = act_fun_dict[act](xi)\n",
    "                y.backward()\n",
    "                xgrad.append(xi.grad)\n",
    "            return torch.tensor(xgrad)\n",
    "        else:\n",
    "            x = x.clone().detach().requires_grad_(True)\n",
    "            y = act_fun_dict[act](x)\n",
    "            y.backward()\n",
    "            return x.grad\n",
    "    else:\n",
    "        raise ValueError(\"This activation function is unknown or unsupported at the moment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "3ae4a96c-1705-4e32-bca2-5356a5cabef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters for the montecarlo integration\n",
    "left_lim = -1000\n",
    "right_lim = 1000\n",
    "tot_num_points = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6bd42e-f841-4623-be16-51b908b78af0",
   "metadata": {},
   "source": [
    "This is actually the LHS of Eq. Eq. (5.73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "ce034a3e-2b96-4cbe-bcd0-5616a4c432d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lhs(k, act = \"ReLU\"):\n",
    "    if not(torch.is_tensor(k)):\n",
    "        k = torch.tensor(k)\n",
    "    x = torch.linspace(left_lim,right_lim,tot_num_points)\n",
    "    norm = torch.sqrt(2*torch.pi*k.clone().detach())\n",
    "    #this is the expected value of the square of the derivative of the activation function\n",
    "    expval1 = ((sum(((der_act(x,act))**2)*np.exp(-x**2/(2*k)))/norm)/tot_num_points)*(right_lim-left_lim)\n",
    "    expval1.shape\n",
    "    #this is the expected value appearing in the denominator of the LHS of (5.73)\n",
    "    expval2 = ((sum( (((act_fun(x,act))**2)*(x**2-k))  * np.exp(-x**2/(2*k))  )/norm)/tot_num_points)*(right_lim-left_lim)\n",
    "    return 2*(k**2) *expval1 / expval2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4952de6-fee7-44ab-ba21-ce36c0510c06",
   "metadata": {},
   "source": [
    "Compute the value of the LHS of Eq. (5.73) numerically, and plot it for $K\\in [0,3]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "97cb8e00-f714-4854-8ff5-37dc815dcdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kvals = torch.logspace(-2,1/2,10)\n",
    "lhsvec = torch.tensor([lhs(k,act = \"Tanh\") for k in kvals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "d2119788-a739-4d89-8acc-fb98f4173289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcc108370a0>]"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (6,6))\n",
    "ax.set_xlim([min(kvals),3])\n",
    "ax.set_ylim([0,5])\n",
    "ax.set_ylabel('LHS')\n",
    "ax.set_xlabel('K')\n",
    "ax.plot(kvals,lhsvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd00a5f-b147-4114-923b-c37f1d6cd088",
   "metadata": {},
   "source": [
    "Now we run the bisection routine to find a solution to LHS - 1 = 0 numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "894eeeb0-3688-49cc-abe3-4a5011e5ff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kstar, fkstar = bisect(lambda k: lhs(k, act = \"Tanh\")-1, 0.02,3, tolerance = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "d8925938-3e46-4f7a-8e21-a1eb3f99bff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The critical value of K is 0.02\n"
     ]
    }
   ],
   "source": [
    "print(f'The critical value of K is {kstar}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff1f0ab-44fc-4bc8-9232-4ff00250d3f4",
   "metadata": {},
   "source": [
    "Notice there is a non-negligible numerical error, noticeable in the plot, too, so we have to pump up the tolerance quite a bit. Indeed the value of f at K* is not really 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "243e0d05-a3ac-4e5b-af71-814865febb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05869615\n"
     ]
    }
   ],
   "source": [
    "print(fkstar.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
